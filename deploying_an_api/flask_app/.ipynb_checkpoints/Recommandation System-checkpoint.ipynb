{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Input, Embedding, Flatten, Dot, Concatenate, Dense, Activation\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_ID = '9G08LOYFU88BJ8GHNRU3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://35.180.16.68/predict?user_id=aaaa&predicted_score=0.761\n",
    "#http://35.180.16.68/reset?user_id=aaaa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = 'http://52.47.62.31/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url=env+'reset', params= {'user_id':USER_ID})\n",
    "sleep(0.05)\n",
    "data = r.json()\n",
    "nb_items = data['nb_items']\n",
    "nb_users = data['nb_users']\n",
    "next_item = data['next_item']\n",
    "next_user = data['next_user']\n",
    "item_history = data['item_history']\n",
    "user_history = data['user_history']\n",
    "rating_history = data['rating_history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.DataFrame(data={'user_id':user_history, 'item_id':item_history, 'rating': rating_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>296</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>282</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>270</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>87</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating\n",
       "0       29      296       3\n",
       "1        0      282       2\n",
       "2       17      270       1\n",
       "3       62       81       4\n",
       "4       32       87       5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_input = Input(shape=[1],name='user')\n",
    "item_id_input = Input(shape=[1], name='item')\n",
    "\n",
    "embedding_size = 5\n",
    "user_embedding = Embedding(output_dim=embedding_size, input_dim=nb_users + 1,\n",
    "                           input_length=1, name='user_embedding')(user_id_input)\n",
    "\n",
    "item_embedding = Embedding(output_dim=embedding_size, input_dim=nb_items + 1,\n",
    "                           input_length=1, name='item_embedding')(item_id_input)\n",
    "\n",
    "user_vecs = Flatten()(user_embedding)\n",
    "item_vecs = Flatten()(item_embedding)\n",
    "\n",
    "y = Dot(axes=1)([user_vecs, item_vecs])\n",
    "\n",
    "model = Model(inputs=[user_id_input, item_id_input], outputs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user (InputLayer)               (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item (InputLayer)               (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_embedding (Embedding)      (None, 1, 5)         505         user[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "item_embedding (Embedding)      (None, 1, 5)         1505        item[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 5)            0           user_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 5)            0           item_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1)            0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,010\n",
      "Trainable params: 2,010\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 9.6570 - val_loss: 9.9388\n",
      "Epoch 2/20\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 9.6160 - val_loss: 9.8043\n",
      "Epoch 3/20\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 9.2005 - val_loss: 9.0123\n",
      "Epoch 4/20\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 8.0223 - val_loss: 7.4776\n",
      "Epoch 5/20\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 6.3231 - val_loss: 5.6894\n",
      "Epoch 6/20\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 4.6332 - val_loss: 4.0981\n",
      "Epoch 7/20\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 3.2487 - val_loss: 2.8645\n",
      "Epoch 8/20\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 2.2407 - val_loss: 2.0039\n",
      "Epoch 9/20\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 1.5628 - val_loss: 1.4360\n",
      "Epoch 10/20\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 1.1291 - val_loss: 1.0764\n",
      "Epoch 11/20\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.8625 - val_loss: 0.8576\n",
      "Epoch 12/20\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.7023 - val_loss: 0.7249\n",
      "Epoch 13/20\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.6084 - val_loss: 0.6468\n",
      "Epoch 14/20\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.5543 - val_loss: 0.6011\n",
      "Epoch 15/20\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.5226 - val_loss: 0.5745\n",
      "Epoch 16/20\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.5047 - val_loss: 0.5579\n",
      "Epoch 17/20\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.4948 - val_loss: 0.5495\n",
      "Epoch 18/20\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.4890 - val_loss: 0.5444\n",
      "Epoch 19/20\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.4862 - val_loss: 0.5423\n",
      "Epoch 20/20\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.4844 - val_loss: 0.5399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa8706c3be0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "model.fit([ratings['user_id'], ratings['item_id']], ratings['rating'],\n",
    "                    batch_size=64, epochs=20, validation_split=0.1,\n",
    "                    shuffle=True, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90 samples, validate on 10 samples\n",
      "Epoch 1/20\n",
      "90/90 [==============================] - 0s 57us/step - loss: 0.5115 - val_loss: 0.2508\n",
      "Epoch 2/20\n",
      "90/90 [==============================] - 0s 95us/step - loss: 0.5013 - val_loss: 0.2497\n",
      "Epoch 3/20\n",
      "90/90 [==============================] - 0s 87us/step - loss: 0.4852 - val_loss: 0.2486\n",
      "Epoch 4/20\n",
      "90/90 [==============================] - 0s 77us/step - loss: 0.4652 - val_loss: 0.2480\n",
      "Epoch 5/20\n",
      "90/90 [==============================] - 0s 76us/step - loss: 0.4452 - val_loss: 0.2473\n",
      "Epoch 6/20\n",
      "90/90 [==============================] - 0s 122us/step - loss: 0.4200 - val_loss: 0.2466\n",
      "Epoch 7/20\n",
      "90/90 [==============================] - 0s 82us/step - loss: 0.3988 - val_loss: 0.2460\n",
      "Epoch 8/20\n",
      "90/90 [==============================] - 0s 80us/step - loss: 0.3768 - val_loss: 0.2454\n",
      "Epoch 9/20\n",
      "90/90 [==============================] - 0s 137us/step - loss: 0.3572 - val_loss: 0.2449\n",
      "Epoch 10/20\n",
      "90/90 [==============================] - 0s 106us/step - loss: 0.3372 - val_loss: 0.2447\n",
      "Epoch 11/20\n",
      "90/90 [==============================] - 0s 59us/step - loss: 0.3193 - val_loss: 0.2445\n",
      "Epoch 12/20\n",
      "90/90 [==============================] - 0s 84us/step - loss: 0.3019 - val_loss: 0.2443\n",
      "Epoch 13/20\n",
      "90/90 [==============================] - 0s 49us/step - loss: 0.2877 - val_loss: 0.2442\n",
      "Epoch 14/20\n",
      "90/90 [==============================] - 0s 43us/step - loss: 0.2722 - val_loss: 0.2443\n",
      "Epoch 15/20\n",
      "90/90 [==============================] - 0s 58us/step - loss: 0.2602 - val_loss: 0.2443\n",
      "Train on 90 samples, validate on 10 samples\n",
      "Epoch 1/20\n",
      "90/90 [==============================] - 0s 55us/step - loss: 0.6524 - val_loss: 0.2872\n",
      "Epoch 2/20\n",
      "90/90 [==============================] - 0s 89us/step - loss: 0.6429 - val_loss: 0.2884\n",
      "Epoch 3/20\n",
      "90/90 [==============================] - 0s 115us/step - loss: 0.6246 - val_loss: 0.2925\n",
      "Train on 90 samples, validate on 10 samples\n",
      "Epoch 1/20\n",
      "90/90 [==============================] - 0s 63us/step - loss: 0.6105 - val_loss: 0.3742\n",
      "Epoch 2/20\n",
      "90/90 [==============================] - 0s 86us/step - loss: 0.5995 - val_loss: 0.3736\n",
      "Epoch 3/20\n",
      "90/90 [==============================] - 0s 112us/step - loss: 0.5843 - val_loss: 0.3730\n",
      "Epoch 4/20\n",
      "90/90 [==============================] - 0s 98us/step - loss: 0.5616 - val_loss: 0.3726\n",
      "Epoch 5/20\n",
      "90/90 [==============================] - 0s 117us/step - loss: 0.5394 - val_loss: 0.3723\n",
      "Epoch 6/20\n",
      "90/90 [==============================] - 0s 69us/step - loss: 0.5134 - val_loss: 0.3721\n",
      "Epoch 7/20\n",
      "90/90 [==============================] - 0s 64us/step - loss: 0.4892 - val_loss: 0.3718\n",
      "Epoch 8/20\n",
      "90/90 [==============================] - 0s 145us/step - loss: 0.4665 - val_loss: 0.3715\n",
      "Epoch 9/20\n",
      "90/90 [==============================] - 0s 88us/step - loss: 0.4423 - val_loss: 0.3713\n",
      "Epoch 10/20\n",
      "90/90 [==============================] - 0s 126us/step - loss: 0.4216 - val_loss: 0.3711\n",
      "Epoch 11/20\n",
      "90/90 [==============================] - 0s 81us/step - loss: 0.4027 - val_loss: 0.3709\n",
      "Epoch 12/20\n",
      "90/90 [==============================] - 0s 122us/step - loss: 0.3843 - val_loss: 0.3708\n",
      "Epoch 13/20\n",
      "90/90 [==============================] - 0s 87us/step - loss: 0.3660 - val_loss: 0.3708\n",
      "Epoch 14/20\n",
      "90/90 [==============================] - 0s 94us/step - loss: 0.3505 - val_loss: 0.3708\n",
      "Epoch 15/20\n",
      "90/90 [==============================] - 0s 83us/step - loss: 0.3343 - val_loss: 0.3708\n",
      "Epoch 16/20\n",
      "90/90 [==============================] - 0s 74us/step - loss: 0.3200 - val_loss: 0.3707\n",
      "Epoch 17/20\n",
      "90/90 [==============================] - 0s 81us/step - loss: 0.3071 - val_loss: 0.3707\n",
      "Epoch 18/20\n",
      "90/90 [==============================] - 0s 106us/step - loss: 0.2957 - val_loss: 0.3705\n",
      "Epoch 19/20\n",
      "90/90 [==============================] - 0s 90us/step - loss: 0.2841 - val_loss: 0.3705\n",
      "Epoch 20/20\n",
      "90/90 [==============================] - 0s 121us/step - loss: 0.2742 - val_loss: 0.3704\n",
      "Train on 90 samples, validate on 10 samples\n",
      "Epoch 1/20\n",
      "90/90 [==============================] - 0s 81us/step - loss: 0.4839 - val_loss: 0.2422\n",
      "Epoch 2/20\n",
      "90/90 [==============================] - 0s 70us/step - loss: 0.4756 - val_loss: 0.2415\n",
      "Epoch 3/20\n",
      "90/90 [==============================] - 0s 54us/step - loss: 0.4623 - val_loss: 0.2408\n",
      "Epoch 4/20\n",
      "90/90 [==============================] - 0s 77us/step - loss: 0.4442 - val_loss: 0.2405\n",
      "Epoch 5/20\n",
      "90/90 [==============================] - 0s 68us/step - loss: 0.4238 - val_loss: 0.2402\n",
      "Epoch 6/20\n",
      "90/90 [==============================] - 0s 46us/step - loss: 0.4028 - val_loss: 0.2400\n",
      "Epoch 7/20\n",
      "90/90 [==============================] - 0s 71us/step - loss: 0.3815 - val_loss: 0.2402\n",
      "Epoch 8/20\n",
      "90/90 [==============================] - 0s 90us/step - loss: 0.3625 - val_loss: 0.2402\n",
      "Train on 90 samples, validate on 10 samples\n",
      "Epoch 1/20\n",
      "90/90 [==============================] - 0s 76us/step - loss: 0.7123 - val_loss: 0.5977\n",
      "Epoch 2/20\n",
      "90/90 [==============================] - 0s 92us/step - loss: 0.6979 - val_loss: 0.5976\n",
      "Epoch 3/20\n",
      "90/90 [==============================] - 0s 108us/step - loss: 0.6744 - val_loss: 0.5968\n",
      "Epoch 4/20\n",
      "90/90 [==============================] - 0s 170us/step - loss: 0.6481 - val_loss: 0.5957\n",
      "Epoch 5/20\n",
      "90/90 [==============================] - 0s 80us/step - loss: 0.6138 - val_loss: 0.5946\n",
      "Epoch 6/20\n",
      "90/90 [==============================] - 0s 82us/step - loss: 0.5802 - val_loss: 0.5954\n",
      "Epoch 7/20\n",
      "90/90 [==============================] - 0s 67us/step - loss: 0.5500 - val_loss: 0.5968\n",
      "Train on 90 samples, validate on 10 samples\n",
      "Epoch 1/20\n",
      "90/90 [==============================] - 0s 83us/step - loss: 0.5494 - val_loss: 0.3571\n",
      "Epoch 2/20\n",
      "90/90 [==============================] - 0s 94us/step - loss: 0.5399 - val_loss: 0.3563\n",
      "Epoch 3/20\n",
      "90/90 [==============================] - 0s 99us/step - loss: 0.5214 - val_loss: 0.3558\n",
      "Epoch 4/20\n",
      "90/90 [==============================] - 0s 103us/step - loss: 0.4970 - val_loss: 0.3552\n",
      "Epoch 5/20\n",
      "90/90 [==============================] - 0s 81us/step - loss: 0.4730 - val_loss: 0.3544\n",
      "Epoch 6/20\n",
      "90/90 [==============================] - 0s 60us/step - loss: 0.4484 - val_loss: 0.3530\n",
      "Epoch 7/20\n",
      "90/90 [==============================] - 0s 78us/step - loss: 0.4202 - val_loss: 0.3521\n",
      "Epoch 8/20\n",
      "90/90 [==============================] - 0s 78us/step - loss: 0.3972 - val_loss: 0.3513\n",
      "Epoch 9/20\n",
      "90/90 [==============================] - 0s 110us/step - loss: 0.3724 - val_loss: 0.3503\n",
      "Epoch 10/20\n",
      "90/90 [==============================] - 0s 69us/step - loss: 0.3513 - val_loss: 0.3492\n",
      "Epoch 11/20\n",
      "90/90 [==============================] - 0s 95us/step - loss: 0.3307 - val_loss: 0.3483\n",
      "Epoch 12/20\n",
      "90/90 [==============================] - 0s 61us/step - loss: 0.3129 - val_loss: 0.3475\n",
      "Epoch 13/20\n",
      "90/90 [==============================] - 0s 91us/step - loss: 0.2955 - val_loss: 0.3468\n",
      "Epoch 14/20\n",
      "90/90 [==============================] - 0s 83us/step - loss: 0.2783 - val_loss: 0.3458\n",
      "Epoch 15/20\n",
      "90/90 [==============================] - 0s 116us/step - loss: 0.2640 - val_loss: 0.3449\n",
      "Epoch 16/20\n",
      "90/90 [==============================] - 0s 107us/step - loss: 0.2504 - val_loss: 0.3441\n",
      "Epoch 17/20\n",
      "90/90 [==============================] - 0s 106us/step - loss: 0.2376 - val_loss: 0.3440\n",
      "Epoch 18/20\n",
      "90/90 [==============================] - 0s 56us/step - loss: 0.2259 - val_loss: 0.3434\n",
      "Epoch 19/20\n",
      "90/90 [==============================] - 0s 74us/step - loss: 0.2157 - val_loss: 0.3428\n",
      "Epoch 20/20\n",
      "90/90 [==============================] - 0s 69us/step - loss: 0.2049 - val_loss: 0.3421\n",
      "Train on 90 samples, validate on 10 samples\n",
      "Epoch 1/20\n",
      "90/90 [==============================] - 0s 118us/step - loss: 0.6257 - val_loss: 0.6719\n",
      "Epoch 2/20\n",
      "90/90 [==============================] - 0s 98us/step - loss: 0.6166 - val_loss: 0.6760\n",
      "Epoch 3/20\n",
      "90/90 [==============================] - 0s 99us/step - loss: 0.6007 - val_loss: 0.6827\n",
      "Train on 90 samples, validate on 10 samples\n",
      "Epoch 1/20\n",
      "90/90 [==============================] - 0s 53us/step - loss: 0.4829 - val_loss: 0.8753\n",
      "Epoch 2/20\n",
      "90/90 [==============================] - 0s 83us/step - loss: 0.4743 - val_loss: 0.8788\n",
      "Epoch 3/20\n",
      "90/90 [==============================] - 0s 103us/step - loss: 0.4599 - val_loss: 0.8831\n",
      "Train on 90 samples, validate on 10 samples\n",
      "Epoch 1/20\n",
      "90/90 [==============================] - 0s 68us/step - loss: 0.4028 - val_loss: 0.3849\n",
      "Epoch 2/20\n",
      "90/90 [==============================] - 0s 92us/step - loss: 0.3959 - val_loss: 0.3875\n",
      "Epoch 3/20\n",
      "90/90 [==============================] - 0s 107us/step - loss: 0.3833 - val_loss: 0.3894\n",
      "Train on 90 samples, validate on 10 samples\n",
      "Epoch 1/20\n",
      "90/90 [==============================] - 0s 127us/step - loss: 0.5605 - val_loss: 0.5964\n",
      "Epoch 2/20\n",
      "90/90 [==============================] - 0s 86us/step - loss: 0.5498 - val_loss: 0.6005\n",
      "Epoch 3/20\n",
      "90/90 [==============================] - 0s 66us/step - loss: 0.5309 - val_loss: 0.6047\n",
      "mse:  0.5493998418399285\n"
     ]
    }
   ],
   "source": [
    "nb_samples = 1000\n",
    "mse = 0\n",
    "users_list = []\n",
    "ratings_list = []\n",
    "items_list = []\n",
    "for i in range(nb_samples):\n",
    "    sleep(0.05)\n",
    "    predicted_score = model.predict([[next_user], [next_item]])[0,0]\n",
    "    r = requests.get(url=env + 'predict', params= {'user_id':USER_ID, 'predicted_score':predicted_score})\n",
    "    true_rating = r.json()['rating']\n",
    "    mse += (true_rating - predicted_score)**2\n",
    "    users_list += [next_user]\n",
    "    ratings_list += [true_rating]\n",
    "    items_list += [next_item]\n",
    "    if (i+1)%100 == 0:\n",
    "        model.fit([users_list,items_list], ratings_list, epochs=20)\n",
    "        users_list = []\n",
    "        ratings_list = []\n",
    "        items_list = []\n",
    "    next_item = r.json()['next_item']\n",
    "    next_user = r.json()['next_user']\n",
    "print('mse: ', mse/nb_samples )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = 'http://35.180.254.42/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url=env+'reset', params= {'user_id':USER_ID})\n",
    "sleep(0.05)\n",
    "data = r.json()\n",
    "nb_items = data['nb_items']\n",
    "nb_users = data['nb_users']\n",
    "next_item = data['next_item']\n",
    "next_user = data['next_user']\n",
    "next_variables = data['next_variables']\n",
    "item_history = data['item_history']\n",
    "user_history = data['user_history']\n",
    "rating_history = data['rating_history']\n",
    "variables_history = np.array(data['variables_history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.DataFrame(data={'user_id':user_history, 'item_id':item_history, 'rating': rating_history, 'variable0': variables_history[:,0], 'variable1': variables_history[:,1], 'variable2': variables_history[:,2], 'variable3': variables_history[:,3], 'variable4': variables_history[:,4]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>variable0</th>\n",
       "      <th>variable1</th>\n",
       "      <th>variable2</th>\n",
       "      <th>variable3</th>\n",
       "      <th>variable4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87</td>\n",
       "      <td>229</td>\n",
       "      <td>2</td>\n",
       "      <td>2.510909</td>\n",
       "      <td>2.632904</td>\n",
       "      <td>1.221147</td>\n",
       "      <td>1.134990</td>\n",
       "      <td>1.947096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98</td>\n",
       "      <td>175</td>\n",
       "      <td>3</td>\n",
       "      <td>1.628397</td>\n",
       "      <td>1.510559</td>\n",
       "      <td>-0.232474</td>\n",
       "      <td>1.250706</td>\n",
       "      <td>-1.445449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "      <td>2.517314</td>\n",
       "      <td>1.243695</td>\n",
       "      <td>-0.418713</td>\n",
       "      <td>0.856469</td>\n",
       "      <td>-0.995321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>208</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.087254</td>\n",
       "      <td>1.446267</td>\n",
       "      <td>0.643022</td>\n",
       "      <td>1.197810</td>\n",
       "      <td>1.388350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>93</td>\n",
       "      <td>2</td>\n",
       "      <td>0.338962</td>\n",
       "      <td>1.590852</td>\n",
       "      <td>0.966019</td>\n",
       "      <td>-0.020251</td>\n",
       "      <td>1.282690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  variable0  variable1  variable2  variable3  \\\n",
       "0       87      229       2   2.510909   2.632904   1.221147   1.134990   \n",
       "1       98      175       3   1.628397   1.510559  -0.232474   1.250706   \n",
       "2        6       81       3   2.517314   1.243695  -0.418713   0.856469   \n",
       "3        0      208       3  -1.087254   1.446267   0.643022   1.197810   \n",
       "4       30       93       2   0.338962   1.590852   0.966019  -0.020251   \n",
       "\n",
       "   variable4  \n",
       "0   1.947096  \n",
       "1  -1.445449  \n",
       "2  -0.995321  \n",
       "3   1.388350  \n",
       "4   1.282690  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_input = Input(shape=[1],name='user')\n",
    "item_id_input = Input(shape=[1], name='item')\n",
    "variables_input = Input(shape=[5], name='variables')\n",
    "\n",
    "embedding_size = 5\n",
    "user_embedding = Embedding(output_dim=embedding_size, input_dim=nb_users + 1,\n",
    "                           input_length=1, name='user_embedding')(user_id_input)\n",
    "\n",
    "item_embedding = Embedding(output_dim=embedding_size, input_dim=nb_items + 1,\n",
    "                           input_length=1, name='item_embedding')(item_id_input)\n",
    "\n",
    "user_vecs = Flatten()(user_embedding)\n",
    "item_vecs = Flatten()(item_embedding)\n",
    "#variables_vecs = Flatten()(variables_input)\n",
    "\n",
    "x = Concatenate()([user_vecs, item_vecs, variables_input])\n",
    "\n",
    "x = Dense(100)(x)\n",
    "x = Activation('softmax')(x)\n",
    "\n",
    "x = Dense(30)(x)\n",
    "x = Activation('softmax')(x)\n",
    "\n",
    "x = Dense(1)(x)\n",
    "\n",
    "\n",
    "model = Model(inputs=[user_id_input, item_id_input, variables_input], outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user (InputLayer)               (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item (InputLayer)               (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_embedding (Embedding)      (None, 1, 5)         505         user[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "item_embedding (Embedding)      (None, 1, 5)         1505        item[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 5)            0           user_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 5)            0           item_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "variables (InputLayer)          (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 15)           0           flatten_10[0][0]                 \n",
      "                                                                 flatten_11[0][0]                 \n",
      "                                                                 variables[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 100)          1600        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 100)          0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 30)           3030        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 30)           0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            31          activation_6[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 6,671\n",
      "Trainable params: 6,671\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "1800/1800 [==============================] - 1s 724us/step - loss: 9.9012 - val_loss: 9.5205\n",
      "Epoch 2/20\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 9.5044 - val_loss: 9.1327\n",
      "Epoch 3/20\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 9.1189 - val_loss: 8.7573\n",
      "Epoch 4/20\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 8.7433 - val_loss: 8.3878\n",
      "Epoch 5/20\n",
      "1800/1800 [==============================] - 0s 32us/step - loss: 8.3810 - val_loss: 8.0347\n",
      "Epoch 6/20\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 8.0327 - val_loss: 7.6898\n",
      "Epoch 7/20\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 7.6893 - val_loss: 7.3553\n",
      "Epoch 8/20\n",
      "1800/1800 [==============================] - 0s 30us/step - loss: 7.3553 - val_loss: 7.0262\n",
      "Epoch 9/20\n",
      "1800/1800 [==============================] - 0s 26us/step - loss: 7.0303 - val_loss: 6.7072\n",
      "Epoch 10/20\n",
      "1800/1800 [==============================] - 0s 27us/step - loss: 6.7134 - val_loss: 6.3937\n",
      "Epoch 11/20\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 6.3973 - val_loss: 6.0861\n",
      "Epoch 12/20\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 6.0937 - val_loss: 5.7887\n",
      "Epoch 13/20\n",
      "1800/1800 [==============================] - 0s 26us/step - loss: 5.8012 - val_loss: 5.5044\n",
      "Epoch 14/20\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 5.5222 - val_loss: 5.2354\n",
      "Epoch 15/20\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 5.2583 - val_loss: 4.9793\n",
      "Epoch 16/20\n",
      "1800/1800 [==============================] - 0s 30us/step - loss: 5.0048 - val_loss: 4.7359\n",
      "Epoch 17/20\n",
      "1800/1800 [==============================] - 0s 26us/step - loss: 4.7644 - val_loss: 4.5031\n",
      "Epoch 18/20\n",
      "1800/1800 [==============================] - 0s 31us/step - loss: 4.5385 - val_loss: 4.2863\n",
      "Epoch 19/20\n",
      "1800/1800 [==============================] - 0s 29us/step - loss: 4.3289 - val_loss: 4.0875\n",
      "Epoch 20/20\n",
      "1800/1800 [==============================] - 0s 26us/step - loss: 4.1338 - val_loss: 3.8993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0d2f0ebf28>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "model.fit([ratings['user_id'], ratings['item_id'], ratings[['variable0', 'variable1', 'variable2', 'variable3', 'variable4']]], ratings['rating'],\n",
    "                    batch_size=64, epochs=20, validation_split=0.1,\n",
    "                    shuffle=True, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 0s 93us/step - loss: 3.8652\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 0s 86us/step - loss: 3.8421\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 0s 76us/step - loss: 3.8182\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 0s 134us/step - loss: 3.7942\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 0s 78us/step - loss: 3.7707\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 0s 110us/step - loss: 3.7465\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 0s 72us/step - loss: 3.7224\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 0s 110us/step - loss: 3.7002\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 0s 89us/step - loss: 3.6768\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 0s 89us/step - loss: 3.6552\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 0s 113us/step - loss: 3.6326\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 0s 123us/step - loss: 3.6093\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 0s 97us/step - loss: 3.5866\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 0s 173us/step - loss: 3.5648\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 0s 126us/step - loss: 3.5441\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 0s 141us/step - loss: 3.5245\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 0s 124us/step - loss: 3.5029\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 0s 146us/step - loss: 3.4829\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 0s 103us/step - loss: 3.4638\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 0s 145us/step - loss: 3.4454\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - 0s 82us/step - loss: 3.2676\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 0s 181us/step - loss: 3.2484\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 0s 103us/step - loss: 3.2293\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 0s 174us/step - loss: 3.2098\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 0s 142us/step - loss: 3.1908\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 0s 139us/step - loss: 3.1727\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 0s 82us/step - loss: 3.1533\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 0s 130us/step - loss: 3.1339\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 0s 104us/step - loss: 3.1160\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 0s 110us/step - loss: 3.0977\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 0s 117us/step - loss: 3.0804\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 0s 96us/step - loss: 3.0639\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 0s 113us/step - loss: 3.0473\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 0s 116us/step - loss: 3.0314\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 0s 131us/step - loss: 3.0153\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 0s 92us/step - loss: 2.9991\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 0s 120us/step - loss: 2.9830\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 0s 158us/step - loss: 2.9670\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 0s 124us/step - loss: 2.9508\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 0s 235us/step - loss: 2.9347\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - 0s 79us/step - loss: 3.3845\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 0s 95us/step - loss: 3.3647\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 0s 107us/step - loss: 3.3435\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 0s 141us/step - loss: 3.3219\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 0s 104us/step - loss: 3.2986\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 0s 154us/step - loss: 3.2751\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 0s 91us/step - loss: 3.2516\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 0s 98us/step - loss: 3.2285\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 0s 88us/step - loss: 3.2059\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 0s 108us/step - loss: 3.1846\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 0s 127us/step - loss: 3.1634\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 0s 102us/step - loss: 3.1424\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 0s 109us/step - loss: 3.1231\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 0s 132us/step - loss: 3.1034\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 0s 131us/step - loss: 3.0828\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 0s 130us/step - loss: 3.0647\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 0s 159us/step - loss: 3.0456\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 0s 114us/step - loss: 3.0266\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 0s 118us/step - loss: 3.0091\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 0s 131us/step - loss: 2.9924\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - 0s 95us/step - loss: 3.2254\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 0s 74us/step - loss: 3.2105\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 0s 71us/step - loss: 3.1952\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 0s 66us/step - loss: 3.1799\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 0s 58us/step - loss: 3.1633\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 0s 57us/step - loss: 3.1496\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 0s 123us/step - loss: 3.1351\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 0s 83us/step - loss: 3.1207\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 0s 118us/step - loss: 3.1059\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 0s 112us/step - loss: 3.0918\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 0s 112us/step - loss: 3.0754\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 0s 129us/step - loss: 3.0586\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 0s 101us/step - loss: 3.0442\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 0s 102us/step - loss: 3.0281\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 0s 88us/step - loss: 3.0122\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 0s 77us/step - loss: 2.9961\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 0s 102us/step - loss: 2.9831\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 0s 95us/step - loss: 2.9690\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 0s 109us/step - loss: 2.9562\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 0s 121us/step - loss: 2.9423\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - 0s 107us/step - loss: 2.5890\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 0s 98us/step - loss: 2.5745\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 0s 122us/step - loss: 2.5595\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 0s 90us/step - loss: 2.5451\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 0s 144us/step - loss: 2.5315\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 0s 90us/step - loss: 2.5168\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 0s 99us/step - loss: 2.5023\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 0s 119us/step - loss: 2.4888\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 0s 115us/step - loss: 2.4746\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 0s 112us/step - loss: 2.4613\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 0s 108us/step - loss: 2.4475\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 0s 115us/step - loss: 2.4340\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 0s 134us/step - loss: 2.4204\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 0s 136us/step - loss: 2.4063\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 0s 116us/step - loss: 2.3925\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 0s 71us/step - loss: 2.3802\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 0s 118us/step - loss: 2.3668\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 0s 84us/step - loss: 2.3551\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 126us/step - loss: 2.3424\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 0s 133us/step - loss: 2.3299\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - 0s 113us/step - loss: 2.3318\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 0s 92us/step - loss: 2.3211\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 0s 110us/step - loss: 2.3113\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 0s 86us/step - loss: 2.3012\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 0s 109us/step - loss: 2.2905\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 0s 129us/step - loss: 2.2804\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 0s 99us/step - loss: 2.2711\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 0s 110us/step - loss: 2.2607\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 0s 114us/step - loss: 2.2523\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 0s 97us/step - loss: 2.2434\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 0s 82us/step - loss: 2.2347\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 0s 105us/step - loss: 2.2255\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 0s 82us/step - loss: 2.2168\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 0s 87us/step - loss: 2.2092\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 0s 108us/step - loss: 2.2003\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 0s 76us/step - loss: 2.1927\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 0s 146us/step - loss: 2.1844\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 0s 159us/step - loss: 2.1761\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 0s 126us/step - loss: 2.1684\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 0s 135us/step - loss: 2.1602\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - 0s 106us/step - loss: 2.2375\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 0s 74us/step - loss: 2.2266\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 0s 70us/step - loss: 2.2160\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 0s 85us/step - loss: 2.2055\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 0s 80us/step - loss: 2.1960\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 0s 111us/step - loss: 2.1857\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 0s 107us/step - loss: 2.1759\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 0s 86us/step - loss: 2.1659\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 0s 106us/step - loss: 2.1566\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 0s 118us/step - loss: 2.1458\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 0s 124us/step - loss: 2.1370\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 0s 106us/step - loss: 2.1260\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 0s 111us/step - loss: 2.1164\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 0s 124us/step - loss: 2.1072\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 0s 90us/step - loss: 2.0981\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 0s 124us/step - loss: 2.0879\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 0s 99us/step - loss: 2.0784\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 0s 91us/step - loss: 2.0686\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 0s 102us/step - loss: 2.0593\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 0s 119us/step - loss: 2.0491\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - 0s 86us/step - loss: 1.8323\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 0s 83us/step - loss: 1.8268\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 0s 117us/step - loss: 1.8212\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 0s 115us/step - loss: 1.8152\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 0s 109us/step - loss: 1.8090\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 0s 67us/step - loss: 1.8029\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 0s 104us/step - loss: 1.7971\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 0s 86us/step - loss: 1.7906\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 0s 74us/step - loss: 1.7841\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 0s 110us/step - loss: 1.7777\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 0s 93us/step - loss: 1.7712\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 0s 143us/step - loss: 1.7641\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 0s 135us/step - loss: 1.7568\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 0s 148us/step - loss: 1.7490\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 0s 137us/step - loss: 1.7411\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 0s 104us/step - loss: 1.7332\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 0s 97us/step - loss: 1.7246\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 0s 121us/step - loss: 1.7164\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 0s 119us/step - loss: 1.7077\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 0s 75us/step - loss: 1.6988\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - 0s 72us/step - loss: 2.0830\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 0s 81us/step - loss: 2.0753\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 0s 108us/step - loss: 2.0670\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 0s 64us/step - loss: 2.0579\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 0s 63us/step - loss: 2.0475\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 0s 70us/step - loss: 2.0381\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 0s 82us/step - loss: 2.0271\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 0s 76us/step - loss: 2.0165\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 0s 112us/step - loss: 2.0052\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 0s 94us/step - loss: 1.9948\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 0s 107us/step - loss: 1.9837\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 0s 82us/step - loss: 1.9736\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 0s 86us/step - loss: 1.9631\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 0s 105us/step - loss: 1.9528\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 0s 104us/step - loss: 1.9421\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 0s 79us/step - loss: 1.9316\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 0s 112us/step - loss: 1.9211\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 0s 120us/step - loss: 1.9109\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 0s 98us/step - loss: 1.9003\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 0s 96us/step - loss: 1.8905\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - 0s 109us/step - loss: 1.5540\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 0s 85us/step - loss: 1.5478\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 0s 122us/step - loss: 1.5410\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 0s 113us/step - loss: 1.5340\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 0s 128us/step - loss: 1.5264\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 0s 90us/step - loss: 1.5199\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 0s 90us/step - loss: 1.5125\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 0s 116us/step - loss: 1.5053\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 0s 101us/step - loss: 1.4988\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 0s 101us/step - loss: 1.4921\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 0s 81us/step - loss: 1.4862\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 0s 101us/step - loss: 1.4793\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 0s 115us/step - loss: 1.4732\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 0s 84us/step - loss: 1.4667\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 0s 82us/step - loss: 1.4609\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 0s 79us/step - loss: 1.4544\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 98us/step - loss: 1.4482\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 0s 78us/step - loss: 1.4419\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 0s 103us/step - loss: 1.4354\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 0s 94us/step - loss: 1.4284\n",
      "mse:  2.6403931859825285\n"
     ]
    }
   ],
   "source": [
    "nb_samples = 1000\n",
    "mse = 0\n",
    "users_list = []\n",
    "ratings_list = []\n",
    "items_list = []\n",
    "variables_list = []\n",
    "for i in range(nb_samples):\n",
    "    sleep(0.05)\n",
    "    predicted_score = model.predict([[next_user], [next_item], [next_variables]])[0,0]\n",
    "    r = requests.get(url=env + 'predict', params= {'user_id':USER_ID, 'predicted_score':predicted_score})\n",
    "    true_rating = r.json()['rating']\n",
    "    mse += (true_rating - predicted_score)**2\n",
    "    users_list += [next_user]\n",
    "    ratings_list += [true_rating]\n",
    "    items_list += [next_item]\n",
    "    variables_list += [next_variables]\n",
    "    if (i+1)%100 == 0:\n",
    "        model.fit([users_list, items_list, variables_list], ratings_list, epochs=20)\n",
    "        users_list = []\n",
    "        ratings_list = []\n",
    "        items_list = []\n",
    "        variables_list = []\n",
    "    next_item = r.json()['next_item']\n",
    "    next_user = r.json()['next_user']\n",
    "    next_variables = r.json()['next_variables']\n",
    "print('mse: ', mse/nb_samples )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
